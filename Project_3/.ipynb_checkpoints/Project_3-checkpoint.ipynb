{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3\n",
    "\n",
    "## Getting Insights into Images and their Metadata\n",
    "\n",
    "\n",
    "Analysis will include:\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import scipy\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import models, transforms\n",
    "import sqlite3\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/katy/anaconda3/envs/mlds/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/katy/anaconda3/envs/mlds/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "vgg16 = torchvision.models.vgg16(pretrained=True) # very slow command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 8, 8])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vgg16.features is a series of modules.\n",
    "# we can chain an input through the modules via the forward method.\n",
    "phi = vgg16.features.forward\n",
    "\n",
    "def preprocess_image(img):\n",
    "\n",
    "    # commented out lines are (probably) unnecessary? I hope?\n",
    "    transform = transforms.Compose([\n",
    "        #transforms.Resize(256), # or 224\n",
    "        #transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    batch = transform(img)\n",
    "    # batch = torch.unsqueeze(batch, 0)\n",
    "    return batch \n",
    "\n",
    "def fetch_img(img_index:int, healthy:bool=True):\n",
    "    if healthy:\n",
    "        return Image.open(f\"Apple___healthy/image ({img_index}).JPG\")\n",
    "    else:\n",
    "        return Image.open(f\"Apple___Black_rot/image ({img_index}).JPG\")\n",
    "\n",
    "def img_features(img_index:int, healthy:bool=True):\n",
    "    return phi(preprocess_image(fetch_img(img_index, healthy=healthy)))\n",
    "\n",
    "phi_out_shape = img_features(1, healthy=True).shape\n",
    "phi_out_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "1D tensors expected, but got 3D and 3D tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/katy/code/mlds/MLFDS/Project_3/Project_3.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/katy/code/mlds/MLFDS/Project_3/Project_3.ipynb#W2sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mdot(w, img_features(img_index, healthy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/katy/code/mlds/MLFDS/Project_3/Project_3.ipynb#W2sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# see if we can correctly identify the first healthy/unhealthy leaves not in the training set\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/katy/code/mlds/MLFDS/Project_3/Project_3.ipynb#W2sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m test_healthy \u001b[39m=\u001b[39m img_guess(\u001b[39m11\u001b[39;49m, healthy\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/katy/code/mlds/MLFDS/Project_3/Project_3.ipynb#W2sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m test_unhealthy \u001b[39m=\u001b[39m img_guess(\u001b[39m11\u001b[39m, healthy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/katy/code/mlds/MLFDS/Project_3/Project_3.ipynb#W2sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m test_healthy, test_unhealthy\n",
      "\u001b[1;32m/Users/katy/code/mlds/MLFDS/Project_3/Project_3.ipynb Cell 5\u001b[0m in \u001b[0;36mimg_guess\u001b[0;34m(img_index, healthy)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/katy/code/mlds/MLFDS/Project_3/Project_3.ipynb#W2sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mimg_guess\u001b[39m(img_index, healthy \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m): \u001b[39m# g(x) from the project3 pdf\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/katy/code/mlds/MLFDS/Project_3/Project_3.ipynb#W2sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mdot(w, img_features(img_index, healthy\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: 1D tensors expected, but got 3D and 3D tensors"
     ]
    }
   ],
   "source": [
    "def mean_features(indices, healthy=True):\n",
    "    mean = None\n",
    "    for x in indices:\n",
    "        if mean is None:\n",
    "            mean = img_features(x, healthy=healthy)\n",
    "        mean += img_features(x, healthy=healthy)\n",
    "    return mean\n",
    "\n",
    "training_indices = range(1, 6) # first few images as training set. Can always be changed later.\n",
    "\n",
    "mean_healthy = mean_features(training_indices, healthy=True)\n",
    "mean_rotted = mean_features(training_indices, healthy=False)\n",
    "\n",
    "w = mean_rotted - mean_healthy\n",
    "w = torch.transpose( w / torch.linalg.norm(w), 0, 1 )\n",
    "\n",
    "def guess(x):\n",
    "    return torch.dot(w, phi(x))\n",
    "\n",
    "def img_guess(img_index, healthy = True): # g(x) from the project3 pdf\n",
    "    return torch.dot(w, img_features(img_index, healthy=True))\n",
    "\n",
    "# see if we can correctly identify the first healthy/unhealthy leaves not in the training set\n",
    "test_healthy = img_guess(11, healthy=True)\n",
    "test_unhealthy = img_guess(11, healthy=False)\n",
    "\n",
    "test_healthy, test_unhealthy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
